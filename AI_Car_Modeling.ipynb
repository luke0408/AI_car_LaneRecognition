{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315ada28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-608feec86c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# 필요 라이브러리 가져오기\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Conv2D, Activation, MaxPool2D, Flatten, Dense, Add\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015890ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 사용되는 이미지 크기 설정 및 데이터 분류 개수\n",
    "input_height = 48\n",
    "input_width = 48\n",
    "input_channel = 3\n",
    "\n",
    "input_shape = (input_height, input_width, input_channel)\n",
    "n_classes = 5  # left, stop, forward, school, noSign \n",
    "\n",
    "# 인공지능 학습에 사용되는 이미지 데이터 위치 지정\n",
    "data_dir = './data'\n",
    "data1_path = os.path.join(data_dir, 'Left', '*.jpg')\n",
    "data1_files = glob.glob(data1_path)\n",
    "data2_path = os.path.join(data_dir, 'Forward', '*.jpg')\n",
    "data2_files = glob.glob(data2_path)\n",
    "data3_path = os.path.join(data_dir, 'Stop', '*.jpg')\n",
    "data3_files = glob.glob(data3_path)\n",
    "data4_path = os.path.join(data_dir, 'schoolZone', '*.jpg')\n",
    "data4_files = glob.glob(data4_path)\n",
    "data5_path = os.path.join(data_dir, 'noSign', '*.jpg')\n",
    "data5_files = glob.glob(data5_path)\n",
    "\n",
    "test_path = os.path.join(data_dir, 'Test', '*.jpg')\n",
    "test_files = glob.glob(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b448ee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 인공지능 학습에 사용되는 이미지의 총 개수 계산\n",
    "n_train = len(data1_files) + len(data2_files) + len(data3_files) + len(data4_files) + len(data5_files)\n",
    "n_test = len(test_files)\n",
    "print(n_train)\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877660b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 학습 데이터 및 레이블이 들어갈 변수 초기화\n",
    "trainset = np.zeros(\n",
    "    shape=(n_train, input_height, input_width, \n",
    "           input_channel), dtype='float32')\n",
    "\n",
    "label = np.zeros(\n",
    "    shape=(n_train, n_classes), dtype='float32')\n",
    "\n",
    "testset = np.zeros(\n",
    "    shape=(n_test, input_height, input_width, \n",
    "           input_channel), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adfd357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 학습에 사용될 이미지 데이터 파일 전체\n",
    "train_files = data1_files + data2_files + data3_files + data4_files + data5_files\n",
    "# 인공지능 학습에 사용될 이미지 데이터 크기 조정\n",
    "# 훈련데이터 셋에 저장\n",
    "for ind, file in enumerate(train_files):\n",
    "    try:\n",
    "        image = cv2.imread(file)\n",
    "        resized_image = cv2.resize(image,\n",
    "                        (input_width, input_height))\n",
    "        trainset[ind] = resized_image\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "\n",
    "# 인공지능 학습 후 평가를 위해 사용될 이미지 데이터 크기 조정\n",
    "# 평가데이터 셋에 저장\n",
    "for ind, file in enumerate(test_files):\n",
    "    try:\n",
    "        image = cv2.imread(file)\n",
    "        resized_image = cv2.resize(image,\n",
    "                            (input_width, input_height))\n",
    "        testset[ind] = resized_image\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "\n",
    "# 훈련데이터 및 평가데이터를 0과 1 수로 변환\n",
    "trainset = trainset / 255.0\n",
    "testset = testset / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ce31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 신호별 데이터 파일 전체 개수 저장\n",
    "n_data1 = len(data1_files)\n",
    "n_data2 = len(data2_files)\n",
    "n_data3 = len(data3_files)\n",
    "n_data4 = len(data4_files)\n",
    "n_data5 = len(data5_files)\n",
    "\n",
    "\n",
    "# 이미지 신호별 레이블 값 정의\n",
    "begin_ind = 0\n",
    "end_ind = n_data1\n",
    "label[begin_ind:end_ind, 0] = 1.0\n",
    "\n",
    "begin_ind = n_data1\n",
    "end_ind = n_data1 + n_data2\n",
    "label[begin_ind:end_ind, 1] = 1.0\n",
    "\n",
    "begin_ind = n_data1 + n_data2\n",
    "end_ind = n_data1 + n_data2 + n_data3\n",
    "label[begin_ind:end_ind, 2] = 1.0\n",
    "\n",
    "begin_ind = n_data1 + n_data2 + n_data3\n",
    "end_ind = n_data1 + n_data2 + n_data3 + n_data4\n",
    "label[begin_ind:end_ind, 3] = 1.0\n",
    "\n",
    "begin_ind = n_data1 + n_data2 + n_data3 + n_data4\n",
    "end_ind = n_data1 + n_data2 + n_data3 + n_data4 + n_data5\n",
    "label[begin_ind:end_ind, 4] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e59b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델을 만드는 함수\n",
    "def custom_model(input_shape, n_classes):\n",
    "\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    x = conv_block(input_tensor, 32)\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 256)\n",
    "    x = conv_block(x, 512)\n",
    "\n",
    "    x = Flatten() (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = Dense(512, activation='relu') (x)\n",
    "    x = Dense(512, activation='relu') (x)\n",
    "\n",
    "    output_layer = Dense(n_classes, activation='softmax') (x)\n",
    "\n",
    "    inputs = [input_tensor]\n",
    "    model = Model(inputs, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68c36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델을 만드는 함수\n",
    "def conv_block(x, filters):\n",
    "    x = BatchNormalization() (x)\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same') (x)\n",
    "\n",
    "    x = BatchNormalization() (x)\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same') (x)\n",
    "    x = Add() ([x, shortcut])\n",
    "    x = MaxPool2D((2, 2), strides=(2, 2)) (x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd4c314",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4d3237efd48f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-4d3237efd48f>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# 모델 함수 호출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# 인공지능 모델을 이용한 최적 데이터 학습 방법 설계\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d78e7be1c6c0>\u001b[0m in \u001b[0;36mcustom_model\u001b[1;34m(input_shape, n_classes)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "# 메인함수\n",
    "def main():\n",
    "    \n",
    "    # 모델 함수 호출\n",
    "    model = custom_model(input_shape, n_classes)\n",
    "    \n",
    "    # 인공지능 모델을 이용한 최적 데이터 학습 방법 설계\n",
    "    adam=Adam()\n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # 인공지능 모델을 이용한 데이터 학습 실행\n",
    "    history = model.fit(\n",
    "        trainset, label, \n",
    "        batch_size=20, \n",
    "        epochs=20,  \n",
    "        validation_split=0.005)\n",
    "            \n",
    "    # 인공지능 학습 후 모델 파일(model.json) 저장\n",
    "    # 가중치 값 파일(weights.h5) 저장\n",
    "    model_desc = model.to_json()\n",
    "    with open('./model/model.json', 'w') as file_model:\n",
    "        file_model.write(model_desc)\n",
    "    model.save_weights('./model/weights.h5')\n",
    "\n",
    "    # 평가데이터를 이용한 예측 정확도 확인\n",
    "    if testset.shape[0] != 0:\n",
    "        result_onehot = model.predict(testset)\n",
    "        result_predict = np.argmax(result_onehot, axis=1)\n",
    "    else:\n",
    "        result_sparse = list()\n",
    "\n",
    "    print('File name\\t forecast category')\n",
    "\n",
    "    # 평가 데이터 파일명에 따른 예측 결과 값 출력\n",
    "    for file, label_id in zip(test_files, result_predict):\n",
    "        \n",
    "        filename = os.path.basename(file)\n",
    "        \n",
    "        if label_id == 0:\n",
    "            label_name = 'Left'\n",
    "        elif label_id == 1:\n",
    "            label_name = 'Forward'\n",
    "        elif label_id == 2:\n",
    "            label_name = 'Stop'\n",
    "        elif label_id == 3:\n",
    "            label_name = 'School Zone'\n",
    "        elif label_id == 4:\n",
    "            label_name = 'noSign'\n",
    "\n",
    "        print('%s\\t%s' % (filename, label_name))\n",
    "        \n",
    "    # 모델 요약 및 학습 진행 결과 출력\n",
    "    model.summary()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83bf29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
